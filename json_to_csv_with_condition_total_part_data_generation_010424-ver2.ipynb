{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3118087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "\n",
    "def extract_context_sentences(utterances, target_index, context_size=5):\n",
    "    context_start_index = max(0, target_index - context_size)\n",
    "    context_end_index = min(len(utterances), target_index + context_size + 1)\n",
    "    context_sentences = utterances[context_start_index:context_end_index]\n",
    "    return context_sentences\n",
    "\n",
    "def extract_metadata_titles(folder_path):\n",
    "    metadata_titles_with_caret = []\n",
    "    metadata_titles_data = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        if filename.endswith('.json'):\n",
    "            with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "                data = json.load(json_file)\n",
    "                document = data.get('document', [{}])[0]\n",
    "                utterances = document.get('utterance', [])\n",
    "                for i, utterance in enumerate(utterances):\n",
    "                    utterance_form = utterance.get('form', '')\n",
    "                    if '^^' in utterance_form:\n",
    "                        metadata_title = data.get('metadata', {}).get('title', '')\n",
    "                        metadata_titles_with_caret.append((filename, metadata_title, i, utterances))\n",
    "                        metadata_titles_data.append(data)\n",
    "                        \n",
    "    return metadata_titles_with_caret, metadata_titles_data\n",
    "\n",
    "def create_csv_with_context_sentences(folder_path, metadata_titles_with_caret, metadata_titles_data, csv_file):\n",
    "    with open(csv_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['setting_relation', 'setting_intimacy', 'setting_contact_frequency', 'document_topic', 'sentence_utterance_id', 'speaker_id', 'utterance_form', 'sentence_time', 'speaker_age', 'speaker_occupation', 'speaker_sex'])\n",
    "        \n",
    "        for (filename, metadata_title, target_index, utterances), data in zip(metadata_titles_with_caret, metadata_titles_data):\n",
    "            document = data.get('document', [{}])[0]\n",
    "            document_title = document.get('metadata', {}).get('title', '')\n",
    "            document_topic = document.get('metadata', {}).get('topic', '')\n",
    "            setting_relation = document.get('metadata', {}).get('setting', {}).get('relation', '')\n",
    "            setting_intimacy = document.get('metadata', {}).get('setting', {}).get('intimacy', '')\n",
    "            setting_contact_frequency = document.get('metadata', {}).get('setting', {}).get('contact_frequency', '')\n",
    "            target_utterance = utterances[target_index]\n",
    "            utterance_form = target_utterance.get('form', '')\n",
    "            utterance_id = target_utterance.get('id', '')\n",
    "            speaker_id = target_utterance.get('speaker_id', '')\n",
    "            speakers = document.get('metadata', {}).get('speaker', [])\n",
    "            speaker_info = next((speaker for speaker in speakers if speaker.get('id') == speaker_id), {})\n",
    "            speaker_age = speaker_info.get('age', '')\n",
    "            speaker_occupation = speaker_info.get('occupation', '')\n",
    "            speaker_sex = speaker_info.get('sex', '')\n",
    "            speaker_birthplace = speaker_info.get('birthplace', '')\n",
    "            speaker_principal_residence = speaker_info.get('pricipal_residence', '')\n",
    "            speaker_current_residence = speaker_info.get('current_residence', '')\n",
    "            speaker_device = speaker_info.get('device', '')\n",
    "            speaker_keyboard = speaker_info.get('keyboard', '')\n",
    "            context_sentences = extract_context_sentences(utterances, target_index)\n",
    "            \n",
    "            for sentence in context_sentences:\n",
    "                sentence_utterance_id = sentence.get('id', '')  # 수정된 부분: 각 context_sentence의 원래 utterance_id\n",
    "                sentence_time = sentence.get('time', '')\n",
    "                speaker_id = sentence.get('speaker_id', '')\n",
    "                speaker_info = next((speaker for speaker in speakers if speaker.get('id') == speaker_id), {})\n",
    "                speaker_age = speaker_info.get('age', '')\n",
    "                speaker_occupation = speaker_info.get('occupation', '')\n",
    "                speaker_sex = speaker_info.get('sex', '')\n",
    "                speaker_birthplace = speaker_info.get('birthplace', '')\n",
    "                speaker_principal_residence = speaker_info.get('pricipal_residence', '')\n",
    "                speaker_current_residence = speaker_info.get('current_residence', '')\n",
    "                speaker_device = speaker_info.get('device', '')\n",
    "                speaker_keyboard = speaker_info.get('keyboard', '')\n",
    "                writer.writerow([setting_relation, setting_intimacy, setting_contact_frequency, document_topic, sentence_utterance_id, speaker_id, sentence.get('form', ''), sentence_time, speaker_age, speaker_occupation, speaker_sex])\n",
    "                \n",
    "                \n",
    "# JSON 파일이 있는 폴더 경로 설정\n",
    "folder_path = \"C:\\\\Users\\\\ArumPark\\\\Desktop\\\\Projekt_Hamburg\\\\NIKL_MESSENGER_v2.0\\\\국립국어원 메신저 말뭉치(버전 2.0)\"\n",
    "\n",
    "# '^^'를 포함하는 utterance_form을 가진 metadata_title을 추출합니다.\n",
    "metadata_titles_with_caret, metadata_titles_data = extract_metadata_titles(folder_path)  # 수정된 부분\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "csv_file_path = './output2.csv'\n",
    "\n",
    "# '^^'를 포함하는 utterance_form을 가진 metadata_title을 가진 JSON 파일만을 선택하여 CSV 파일로 생성합니다.\n",
    "create_csv_with_context_sentences(folder_path, metadata_titles_with_caret, metadata_titles_data, csv_file_path)  # 수정된 부분\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
